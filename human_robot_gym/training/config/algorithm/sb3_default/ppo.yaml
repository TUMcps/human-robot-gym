name: PPO
policy: MlpPolicy
learning_rate: 3e-4
n_steps: 2048
batch_size: 64
n_epochs: 10
gamma: 0.99
gae_lambda: 0.95
clip_range: 0.2
clip_range_vf: null
normalize_advantage: true
ent_coef: 0.0
vf_coef: 0.5
max_grad_norm: 0.5
use_sde: False
sde_sample_freq: -1
target_kl: null
create_eval_env: false
policy_kwargs: null
verbose: 0
seed: null
device: auto
_init_setup_model: true
